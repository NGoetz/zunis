
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>src.training.weighted_dataset.variance_training module &#8212; pytorch_flows 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/overflow.css" />
    
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">pytorch_flows 0.1 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-src.training.weighted_dataset.variance_training">
<span id="src-training-weighted-dataset-variance-training-module"></span><h1>src.training.weighted_dataset.variance_training module<a class="headerlink" href="#module-src.training.weighted_dataset.variance_training" title="Permalink to this headline">¶</a></h1>
<p>Optimization of invertible flows in the weighted dataset problem using the DKL loss</p>
<p>Reminder: we have a dataset (x,p(x),f(x)) such that
- x ~ p(x)
- we want to learn a model that draws points according to f(x),
which is positive, and known up to normalization</p>
<p>We want to optimize a function q(x) such that doing importance sampling to compute f(x)
with it minimizes the variance.</p>
<p>The variance of the importance sampling estimator is our proto-loss</p>
<dl class="simple">
<dt>pL(f,q) =  ∫ dx q(x) (f(x)/q(x))^2 - (∫ dx q(x) f(x)/q(x))^2</dt><dd><p>=  ∫ dx (f(x)^2/q(x)) - I(f)^2</p>
</dd>
</dl>
<p>where I(f) is the integral we want to compute and is independent of q, so our real loss is</p>
<p>L(f,q) = ∫ dx f(x)^2/q(x)</p>
<p>Which we further can compute using importance sampling from p(x):</p>
<p>L(f,q) = ∫ dx p(x) f(x)^2/q(x)/p(x)</p>
<p>Which we can compute from our dataset as the expectation value</p>
<p>L(f,q) = E(f(x)^2/(q(x) p(x)), x~p(x)</p>
<dl class="py class">
<dt id="src.training.weighted_dataset.variance_training.BasicStatefulVarTrainer">
<em class="property">class </em><code class="sig-name descname">BasicStatefulVarTrainer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">flow</span></em>, <em class="sig-param"><span class="n">latent_prior</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#src.training.weighted_dataset.variance_training.BasicStatefulVarTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="src.training.weighted_dataset.weighted_dataset_trainer.html#src.training.weighted_dataset.weighted_dataset_trainer.BasicStatefulTrainer" title="src.training.weighted_dataset.weighted_dataset_trainer.BasicStatefulTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">src.training.weighted_dataset.weighted_dataset_trainer.BasicStatefulTrainer</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt id="src.training.weighted_dataset.variance_training.BasicVarTrainer">
<em class="property">class </em><code class="sig-name descname">BasicVarTrainer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">flow</span></em>, <em class="sig-param"><span class="n">latent_prior</span></em><span class="sig-paren">)</span><a class="headerlink" href="#src.training.weighted_dataset.variance_training.BasicVarTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="src.training.weighted_dataset.weighted_dataset_trainer.html#src.training.weighted_dataset.weighted_dataset_trainer.BasicTrainer" title="src.training.weighted_dataset.weighted_dataset_trainer.BasicTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">src.training.weighted_dataset.weighted_dataset_trainer.BasicTrainer</span></code></a></p>
<p>Basic trainer based on the variance loss</p>
</dd></dl>

<dl class="py function">
<dt id="src.training.weighted_dataset.variance_training.weighted_variance_loss">
<code class="sig-name descname">weighted_variance_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fx</span></em>, <em class="sig-param"><span class="n">px</span></em>, <em class="sig-param"><span class="n">logqx</span></em><span class="sig-paren">)</span><a class="headerlink" href="#src.training.weighted_dataset.variance_training.weighted_variance_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Proxy variance loss for the integral of a function f using importance sampling from q,
but where the variance is estimated with importance sampling from p.</p>
<p>We want to optimize a function q(x) such that doing importance sampling to compute f(x)
with it minimizes the variance.</p>
<p>The variance of the importance sampling estimator is our proto-loss</p>
<dl class="simple">
<dt>pL(f,q) =  ∫ dx q(x) (f(x)/q(x))^2 - (∫ dx q(x) f(x)/q(x))^2</dt><dd><p>=  ∫ dx (f(x)^2/q(x)) - I(f)^2</p>
</dd>
</dl>
<p>where I(f) is the integral we want to compute and is independent of q, so our real loss is</p>
<p>L(f,q) = ∫ dx f(x)^2/q(x)</p>
<p>Which we further can compute using importance sampling from p(x):</p>
<p>L(f,q) = ∫ dx p(x) f(x)^2/q(x)/p(x)</p>
<p>Which we can compute from our dataset as the expectation value</p>
</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/api/src.training.weighted_dataset.variance_training.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">pytorch_flows 0.1 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.3.
    </div>
  </body>
</html>